{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e77bd6",
   "metadata": {},
   "source": [
    "# Image Captioning with BLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ab3a4",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this notebook I will load a snapshot of the DynamoDB table where I have stored all of Reddit posts. For each post containing an image, I will use BLIP: *Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation* to generate a caption, so the fine-tuned LLM can interpret the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45793dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3726925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a0310",
   "metadata": {},
   "source": [
    "## 2. Load and Prep Data\n",
    "Read in the DynamoDB export from S3. This is a `json.gz` file, so I will need to decompress it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c0204d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'submissionId': {'S': '136cmyb'}, 'topComment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'submissionId': {'S': '16ok566'}, 'topComment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'submissionId': {'S': 'poe4fo'}, 'topComment'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'submissionId': {'S': '13xn4b9'}, 'topComment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'submissionId': {'S': 'mprm3j'}, 'topComment'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Item\n",
       "0  {'submissionId': {'S': '136cmyb'}, 'topComment...\n",
       "1  {'submissionId': {'S': '16ok566'}, 'topComment...\n",
       "2  {'submissionId': {'S': 'poe4fo'}, 'topComment'...\n",
       "3  {'submissionId': {'S': '13xn4b9'}, 'topComment...\n",
       "4  {'submissionId': {'S': 'mprm3j'}, 'topComment'..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'sagemaker-us-east-1-513033806411'\n",
    "object_key = 'reddit/funny/AWSDynamoDB/01707665158792-b0452d79/data/lsr2eo7idm6prgqdcvn72k7joa.json.gz'\n",
    "\n",
    "# Get the object from S3\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "content = response['Body'].read()\n",
    "\n",
    "# Decompress and read into a pandas DataFrame\n",
    "with gzip.GzipFile(fileobj=io.BytesIO(content)) as gzipfile:\n",
    "    content = gzipfile.read()\n",
    "\n",
    "df = pd.read_json(io.BytesIO(content), lines=True)  # Assuming the JSON is line-delimited\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0877c2f",
   "metadata": {},
   "source": [
    "Since this is coming from DynamoDB, which doesn't enforce a strict schema, all of the items are stored as JSON objects. I will extract the values to create new columns in the dataframe with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee7041b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submissionId</th>\n",
       "      <th>topComment</th>\n",
       "      <th>numComments</th>\n",
       "      <th>topCommentScore</th>\n",
       "      <th>createdUtc</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136cmyb</td>\n",
       "      <td>No seriously though, what the hell is happenin...</td>\n",
       "      <td>608</td>\n",
       "      <td>2989</td>\n",
       "      <td>1683095752</td>\n",
       "      <td>41173</td>\n",
       "      <td>https://v.redd.it/u050avdqrlxa1</td>\n",
       "      <td>\"So what are your intentions with my daughter?\"</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16ok566</td>\n",
       "      <td>Oh Deere!\\n\\nThis is one of the few times I ca...</td>\n",
       "      <td>645</td>\n",
       "      <td>3557</td>\n",
       "      <td>1695313196</td>\n",
       "      <td>37380</td>\n",
       "      <td>https://i.redd.it/hsp7ro7jwmpb1.jpg</td>\n",
       "      <td>I wonder whose decision it was</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poe4fo</td>\n",
       "      <td>She did this dress so she could send her body ...</td>\n",
       "      <td>1530</td>\n",
       "      <td>5810</td>\n",
       "      <td>1631661684</td>\n",
       "      <td>73128</td>\n",
       "      <td>https://i.redd.it/xtbn4vzdyjn71.jpg</td>\n",
       "      <td>The is me, circa 2014, on the left. Kim Kardas...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13xn4b9</td>\n",
       "      <td>Beth, you are a *horse* surgeon.</td>\n",
       "      <td>1697</td>\n",
       "      <td>8146</td>\n",
       "      <td>1685639071</td>\n",
       "      <td>50443</td>\n",
       "      <td>https://v.redd.it/c1g35aiuce3b1</td>\n",
       "      <td>It's never a veterinarian that they are lookin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mprm3j</td>\n",
       "      <td>This wouldn’t happen to be in Christiansburg V...</td>\n",
       "      <td>973</td>\n",
       "      <td>3074</td>\n",
       "      <td>1618275332</td>\n",
       "      <td>90033</td>\n",
       "      <td>https://i.redd.it/icbg029w9us61.jpg</td>\n",
       "      <td>A local music store in my town has had this si...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submissionId                                         topComment numComments  \\\n",
       "0      136cmyb  No seriously though, what the hell is happenin...         608   \n",
       "1      16ok566  Oh Deere!\\n\\nThis is one of the few times I ca...         645   \n",
       "2       poe4fo  She did this dress so she could send her body ...        1530   \n",
       "3      13xn4b9                   Beth, you are a *horse* surgeon.        1697   \n",
       "4       mprm3j  This wouldn’t happen to be in Christiansburg V...         973   \n",
       "\n",
       "  topCommentScore  createdUtc  score                                  url  \\\n",
       "0            2989  1683095752  41173      https://v.redd.it/u050avdqrlxa1   \n",
       "1            3557  1695313196  37380  https://i.redd.it/hsp7ro7jwmpb1.jpg   \n",
       "2            5810  1631661684  73128  https://i.redd.it/xtbn4vzdyjn71.jpg   \n",
       "3            8146  1685639071  50443      https://v.redd.it/c1g35aiuce3b1   \n",
       "4            3074  1618275332  90033  https://i.redd.it/icbg029w9us61.jpg   \n",
       "\n",
       "                                               title body  \n",
       "0    \"So what are your intentions with my daughter?\"       \n",
       "1                     I wonder whose decision it was       \n",
       "2  The is me, circa 2014, on the left. Kim Kardas...       \n",
       "3  It's never a veterinarian that they are lookin...       \n",
       "4  A local music store in my town has had this si...       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to extract values from the DynamoDB format\n",
    "def extract_values(row):\n",
    "    return {k: list(v.values())[0] for k, v in row.items()}\n",
    "\n",
    "# Apply the transformation to each row in the DataFrame\n",
    "df_transformed = df['Item'].apply(lambda row: extract_values(row))\n",
    "\n",
    "# Convert the series of dictionaries into a DataFrame\n",
    "df_flat = pd.json_normalize(df_transformed)\n",
    "\n",
    "display(df_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2764439e",
   "metadata": {},
   "source": [
    "## 3. Generate Image Captions\n",
    "### a) Load the `Salesforce/blip-image-captioning-large` model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad769e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d06f6f47a54a25b03b6337a49257fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a66f7c7d2b47ea8ca50cc3b4837ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f9ec9989f84964a7f135efba30ad92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4ae74b05524ca8b5aebe3b1b332c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a279e9e5d88844a59ac0e004048c2827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9900a7a093324a4bb4a939a4578153d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892f1ccbaf724cfaba14d4a19d38b421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the pipeline\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff32322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating captions for 1328 images\n"
     ]
    }
   ],
   "source": [
    "image_count = len(df_flat[df_flat['imageS3Url'] != \"N/A\"])\n",
    "print(f\"Generating captions for {image_count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49751f2",
   "metadata": {},
   "source": [
    "### b) Iterate through the images in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1a14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: there are two people standing in a room with a tractor\n",
      "2: a close up of a person in a black dress and a black man in a black suit\n",
      "4: arafed image of a store front with a sign for a super shoes store\n",
      "6: there is a pile of wood sitting in front of a house\n",
      "7: someone is holding a banana in their hand on a tile floor\n",
      "8: cartoon of a man with a computer on his head and a computer on his head\n",
      "9: there is a picture of a toy on a scooter and a picture of a man on a scooter\n",
      "12: there is a cat that is laying inside of a refrigerator\n",
      "13: a close up of a baby sitting in a wooden box\n",
      "15: someone is holding a credit card and a game controller\n",
      "18: a cartoon of a dog looking out a window at a neighbor\n",
      "...\n",
      "2662: a cartoon of a comic strip with a man and a woman talking\n",
      "2663: there is a car that has a sticker on the window\n",
      "2665: there are many men posing for a picture together with one man pointing at the camera\n",
      "2666: cartoon of a group of blue alien with a message saying,'this is our oldest liquid '\n",
      "2668: a cartoon of a dog with a halo and a cat with a bird on it\n",
      "2669: cartoon of a comic strip with a picture of a man and a woman\n",
      "2670: a close up of a sesame street birthday card with a sesame character\n",
      "2671: arafed man with a laptop and a bag of food in his back pocket\n",
      "2672: there is a man with glasses and a beard eating a donut\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_caption_from_s3(bucket_name, object_key):\n",
    "    \"\"\"Generate a caption for the image using BLIP\"\"\"\n",
    "    \n",
    "    # Get the object from S3\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "        image_content = response['Body'].read()\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(io.BytesIO(image_content))\n",
    "\n",
    "        # Generate caption from BLIP\n",
    "        result = image_to_text(image, max_new_tokens=50)\n",
    "        return result[0]['generated_text'] if result else \"Caption not generated\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "# Initialize new description column for BLIP response\n",
    "df['blip_image_description'] = ''\n",
    "\n",
    "# Extract the object key from the S3 URL\n",
    "df_flat['object_key'] = df_flat['imageS3Url'].apply(lambda x: x.replace(f's3://{bucket_name}/', ''))\n",
    "\n",
    "# Generate descriptions for each image by applying the function to the 'object_key' column\n",
    "for i in range(df_flat.shape[0]):\n",
    "    object_key = df_flat.loc[i, 'object_key']\n",
    "    if object_key != 'N/A':\n",
    "        blip_description = generate_caption_from_s3(bucket_name, object_key)\n",
    "        print(f\"{i}: {blip_description}\")\n",
    "    else:\n",
    "        blip_description = 'N/A'\n",
    "    # assign value\n",
    "    df_flat.loc[i, 'blip_image_description'] = blip_description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec6c0f",
   "metadata": {},
   "source": [
    "You might notice that some of these captions have typos like `araffe` and `arafed`. These typically occur where you expect the word to be `A`. For example: \n",
    "- ***araffeed*** *cup of ice cream with a cow on it*\n",
    "- ***araffe*** *milk container with a message written on it*\n",
    "- ***arafed*** *man standing on a muddy bank next to a car*\n",
    "\n",
    "This is a known bug for this model and is believed to be due to huggingface dataset it was trained on. If this problem was a significant issue, I could add logic to remove these typos in the training set, as well as in production where BLIP is interpreting images for the system. However, LLM's handle typos quite well and this shouldn't affect the ability for the fine-tuned model to understand what is being depicted in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee7fc0",
   "metadata": {},
   "source": [
    "### c) Use SageMaker Batch Transform (optional)\n",
    "Iterating through ~1,300 images for this model works here using a `ml.p3.2xlarge` instance type. However, at greater scale, a better option would be using SageMaker Batch Transform to distribute the workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'Salesforce/blip-image-captioning-large',\n",
    "    'HF_TASK':'image-to-text'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.26.0',\n",
    "    pytorch_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    env=hub,\n",
    "    role=role, \n",
    ")\n",
    "\n",
    "model_name = huggingface_model.create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6810b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "# Start a transform job\n",
    "response = sagemaker.create_transform_job(\n",
    "    TransformJobName='blip-image-captioning-transform-job',\n",
    "    ModelName=model_name,  # Use the model name from the model creation step\n",
    "    MaxConcurrentTransforms=4,\n",
    "    MaxPayloadInMB=6,\n",
    "    BatchStrategy='MultiRecord',\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-513033806411/reddit/funny/posts/'}\n",
    "        },\n",
    "        'ContentType': 'application/x-image',  # Ensure this matches the model's expected content type\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': 's3://sagemaker-us-east-1-513033806411/reddit/funny/captions/',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.p3.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59a6e1",
   "metadata": {},
   "source": [
    "## 4. Save Generated Captions\n",
    "Now that the image captions have been generated, I'm going to update the DynamoDB table with the captions as well as save the dataframe to S3 for later use.\n",
    "### a) Update DynamoDB items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da67ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DynamoDB client\n",
    "dynamodb = boto3.client('dynamodb', region_name='us-east-1') \n",
    "\n",
    "def update_dynamodb_table_with_blip(df):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        dynamodb.update_item(\n",
    "            TableName='funny-reddit-posts',\n",
    "            Key={\n",
    "                'submissionId': {'S': str(row['submissionId'])},\n",
    "            },\n",
    "            UpdateExpression='SET blipCaption = :val',\n",
    "            ExpressionAttributeValues={\n",
    "                ':val': {'S': str(row['blip_image_description'])},\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Update items with BLIP caption\n",
    "blip_df = df[~df['blip_image_description'].isna()].reset_index(drop=True)\n",
    "update_dynamodb_table_with_blip(blip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e9cd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to CSV string\n",
    "csv_buffer = io.StringIO()\n",
    "df_flat.to_csv(csv_buffer)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Specify your bucket name and the desired key (path + filename in the bucket)\n",
    "bucket_name = 'sagemaker-us-east-1-513033806411'\n",
    "object_key = 'reddit/funny/data/blip_descriptions.csv'\n",
    "\n",
    "# Upload the CSV string to S3\n",
    "s3_client.put_object(Bucket=bucket_name, Body=csv_buffer.getvalue(), Key=object_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ae37a",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "After this processing, I have image captions for about half of the Reddit posts in my dataset. In the next notebook I will be imputing captions for the posts with missing images (due to gif/video format)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
