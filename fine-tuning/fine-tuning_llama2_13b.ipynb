{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8506d0b2",
   "metadata": {},
   "source": [
    "# Fine-tuning LLaMA 2 13B\n",
    "## 1. Introduction\n",
    "In this notebook, I will fine-tune [LLaMa 2 13B](https://huggingface.co/meta-llama/Llama-2-13b-hf) on the training set procured in previous notebooks. A large part of this will be following the tutorial from https://www.philschmid.de/sagemaker-llama2-qlora. Instead of adjusting the weights of all 13 billion parameters, I am going to use a technique called ***QLoRA***. \n",
    "\n",
    "`\"QLoRA is an efficient finetuning technique that quantizes a pretrained language model to 4 bits and attaches small 'Low-Rank Adapters' which are fine-tuned. This enables fine-tuning of models with up to 65 billion parameters on a single GPU; despite its efficiency, QLoRA matches the performance of full-precision fine-tuning and achieves state-of-the-art results on language tasks.\"`\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## 2. Connect to Hugging Face\n",
    "Access must be granted in order to download the LLaMA models from Meta. To verify access, you must be logged into Hugging Face, so I am going to authenticate with my token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa46b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q accelerate peft bitsandbytes transformers trl datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c605cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1711d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret():\n",
    "    \"\"\"Get secret from AWS Secrets Manager\"\"\"\n",
    "\n",
    "    secret_name = \"reddit_scraper\"\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "\n",
    "    return json.loads(secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64f369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = get_secret()\n",
    "HUGGINGFACE_TOKEN = secret['huggingface_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba0c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token {HUGGINGFACE_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ca9303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::513033806411:role/service-role/AmazonSageMaker-ExecutionRole-20210815T111148\n",
      "sagemaker bucket: sagemaker-us-east-1-513033806411\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Set sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482cbc5",
   "metadata": {},
   "source": [
    "## 3. Load and prepare the dataset\n",
    "Load the dataset from S3 and format for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cabc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submissionId</th>\n",
       "      <th>title</th>\n",
       "      <th>image_description</th>\n",
       "      <th>topComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eqq9j8</td>\n",
       "      <td>In Minnesota, we like to play a game called \"a...</td>\n",
       "      <td>- Description: snowy road with cars driving on...</td>\n",
       "      <td>The first person to drive on a snowy road gets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grrjug</td>\n",
       "      <td>The most suspicious looking technician at toda...</td>\n",
       "      <td>- Description: arafed male doctor in white lab...</td>\n",
       "      <td>“He’s not supposed to be there”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m8kft5</td>\n",
       "      <td>Slip given out at one of my local bars if secu...</td>\n",
       "      <td>- Description: someone is giving a note to som...</td>\n",
       "      <td>I was at a bar in Colorado a few years back an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11fdi6b</td>\n",
       "      <td>My daughter's school don't dress up for world ...</td>\n",
       "      <td>- Description: there is a small white mask wit...</td>\n",
       "      <td>Spud-Who-Must-Not-Be-Named</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a2pc8h</td>\n",
       "      <td>Every year I try to disguise my sister's Chris...</td>\n",
       "      <td>- Description: there is a blue and red present...</td>\n",
       "      <td>I bet it's a new car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submissionId                                              title  \\\n",
       "0       eqq9j8  In Minnesota, we like to play a game called \"a...   \n",
       "1       grrjug  The most suspicious looking technician at toda...   \n",
       "2       m8kft5  Slip given out at one of my local bars if secu...   \n",
       "3      11fdi6b  My daughter's school don't dress up for world ...   \n",
       "4       a2pc8h  Every year I try to disguise my sister's Chris...   \n",
       "\n",
       "                                   image_description  \\\n",
       "0  - Description: snowy road with cars driving on...   \n",
       "1  - Description: arafed male doctor in white lab...   \n",
       "2  - Description: someone is giving a note to som...   \n",
       "3  - Description: there is a small white mask wit...   \n",
       "4  - Description: there is a blue and red present...   \n",
       "\n",
       "                                          topComment  \n",
       "0  The first person to drive on a snowy road gets...  \n",
       "1                    “He’s not supposed to be there”  \n",
       "2  I was at a bar in Colorado a few years back an...  \n",
       "3                         Spud-Who-Must-Not-Be-Named  \n",
       "4                               I bet it's a new car  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Specify your bucket name and the object key\n",
    "bucket_name = 'sagemaker-us-east-1-513033806411'\n",
    "object_key = 'reddit/funny/data/training_data.csv'\n",
    "\n",
    "# Get the object from S3\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "# Read the CSV data into a DataFrame\n",
    "# The 'Body' key of the response contains the file content\n",
    "train_df = pd.read_csv(response['Body'])\n",
    "\n",
    "# Now df contains your data, you can inspect it using df.head()\n",
    "cols = ['submissionId', 'title', 'image_description','topComment']\n",
    "train_df = train_df[cols]\n",
    "\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de98a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['submissionId', 'title', 'image_description', 'topComment'],\n",
      "    num_rows: 2601\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "reddit_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "print(reddit_dataset)  # To verify the conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf2ad5",
   "metadata": {},
   "source": [
    "To instruct tune our model I will convert the structured examples into a collection of tasks described via instructions. Here, I define a `format_reddit()` function that takes a sample and returns a string with our format instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1623f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reddit(sample):\n",
    "    instruction = f\"### Instruction:\\nRespond to this Reddit post with an award winning top comment.\"\n",
    "    context = f\"### Reddit Post:\\n{sample['title']}\\n\\n### Image Context:\\n{sample['image_description']}\" \n",
    "    response = f\"### Response:\\n{sample['topComment']}\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94b9b6",
   "metadata": {},
   "source": [
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d2d295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Respond to this Reddit post with an award winning top comment.\n",
      "\n",
      "### Reddit Post:\n",
      "🦸‍♂️ Iron-Deficiency Man\n",
      "\n",
      "### Image Context:\n",
      "- Description: A person wearing a homemade Iron Man costume made from cardboard and other household materials\n",
      "- Text: \n",
      "- Celebrities: \n",
      "\n",
      "### Response:\n",
      "Love the creative spirit.  Everyone should make their own costumes.  Celebrate creativity over handing your money to corporations.  This guy nailed it.\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "print(format_reddit(reddit_dataset[randrange(len(reddit_dataset))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cb787",
   "metadata": {},
   "source": [
    "Now that the samples are formatted, I am going to pack multiple samples to one sequence for more efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80c12487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:711: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75acce3fa2c475b912f420c2a9de3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bb54ce27ac47e2925312169b48b992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188a167e2ab443f8b39a03f480ba84c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49752b564e4047b69a485268c5166b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-13b-hf\" # sharded weights\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61381923",
   "metadata": {},
   "source": [
    "We define some helper functions to pack our samples into sequences of a given length and then tokenize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23e8b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_reddit(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "# apply prompt template per sample\n",
    "reddit_dataset = reddit_dataset.map(template_dataset, remove_columns=list(reddit_dataset.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0895f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125bd16026234572bff22aa7c9dba027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2601 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6010ba0f2a449a963adf158ee427de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2601 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 212\n"
     ]
    }
   ],
   "source": [
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = reddit_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(reddit_dataset.features)\n",
    ").map(\n",
    "    partial(chunk, chunk_length=2048),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a6280dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 212\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d5d89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e3edeab864c31a93c5dbe2c54693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-us-east-1-513033806411/reddit/funny/data/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "bucket_name = 'sagemaker-us-east-1-513033806411'\n",
    "training_input_path = f's3://{bucket_name}/reddit/funny/data/train'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(f\"uploaded training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e392e1",
   "metadata": {},
   "source": [
    "## 4. Fine-tune LLaMA 13B with QLoRA\n",
    "Now it's time to implement [\"QLoRA: Quantization-aware Low-Rank Adapter Tuning for Language Generation\"](https://arxiv.org/abs/2106.09685). QLoRA introduces an innovative strategy for minimizing the memory usage of extensive language models during fine-tuning processes, all while maintaining their efficiency. In essence, QLoRA's methodology involves:\n",
    "\n",
    "- Compressing the pre-trained model to a 4-bit representation and locking it in place.\n",
    "- Incorporating small, modifiable adapter layers known as LoRA.\n",
    "- Focusing the fine-tuning efforts solely on these adapter layers, utilizing the compressed, static model for contextual guidance.\n",
    "\n",
    "I am going to use Philipp Schmid's script from the tutorial, `run_clm.py`, which utilizes parameter-efficient fine-tuning (PEFT) to facilitate the model's training with QLoRA. This script is also designed to integrate the LoRA weights back into the primary model weights post-training, enabling the use of the model in a standard fashion without necessitating any supplementary coding efforts.\n",
    "\n",
    "In the code below, I create a HuggingFace Estimator and kickoff a SageMaker training job to fine-tune the model and store the artifacts for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cb671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0638472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'epochs': 3,                                      # number of training epochs\n",
    "  'per_device_train_batch_size': 2,                 # batch size for training\n",
    "  'lr': 2e-4,                                       # learning rate used during training\n",
    "  'hf_token': HfFolder.get_token(),                 # huggingface token to access llama 2\n",
    "  'merge_weights': True,                            # wether to merge LoRA into the model (needs more memory)\n",
    "}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_clm.py',      # train script\n",
    "    source_dir           = 'scripts',         # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e466f8",
   "metadata": {},
   "source": [
    "Start the training job with the `.fit()` method, passing the S3 path to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d544217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:16:15 Starting - Starting the training job\n",
      "2024-02-17 17:16:15 Pending - Training job waiting for capacity...\n",
      "2024-02-17 17:16:34 Pending - Preparing the instances for training......\n",
      "2024-02-17 17:17:39 Downloading - Downloading input data...\n",
      "2024-02-17 17:18:14 Downloading - Downloading the training image.....................\n",
      "2024-02-17 17:21:25 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:27,786 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:27,805 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:27,814 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:27,816 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:29,122 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.31.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.9/116.9 kB 9.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.4.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.21.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes==0.40.2 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.40.2-py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.13.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r requirements.txt (line 1)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->-r requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.4/7.4 MB 84.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.4.0-py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 12.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 244.2/244.2 kB 38.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.5/92.5 MB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 70.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, safetensors, transformers, accelerate, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.21.0 bitsandbytes-0.40.2 peft-0.4.0 safetensors-0.4.2 transformers-4.31.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,067 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,067 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,110 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,138 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,166 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,176 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"epochs\": 3,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"lr\": 0.0002,\n",
      "        \"merge_weights\": true,\n",
      "        \"model_id\": \"meta-llama/Llama-2-13b-hf\",\n",
      "        \"per_device_train_batch_size\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-513033806411/huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_clm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_clm.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dataset_path\":\"/opt/ml/input/data/training\",\"epochs\":3,\"hf_token\":\"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\",\"lr\":0.0002,\"merge_weights\":true,\"model_id\":\"meta-llama/Llama-2-13b-hf\",\"per_device_train_batch_size\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_clm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_clm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-513033806411/huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataset_path\":\"/opt/ml/input/data/training\",\"epochs\":3,\"hf_token\":\"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\",\"lr\":0.0002,\"merge_weights\":true,\"model_id\":\"meta-llama/Llama-2-13b-hf\",\"per_device_train_batch_size\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-513033806411/huggingface-qlora-2024-02-17-17-15-24-2024-02-17-17-16-14-114/source/sourcedir.tar.gz\",\"module_name\":\"run_clm\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_clm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dataset_path\",\"/opt/ml/input/data/training\",\"--epochs\",\"3\",\"--hf_token\",\"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\",\"--lr\",\"0.0002\",\"--merge_weights\",\"True\",\"--model_id\",\"meta-llama/Llama-2-13b-hf\",\"--per_device_train_batch_size\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_WEIGHTS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=meta-llama/Llama-2-13b-hf\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_clm.py --dataset_path /opt/ml/input/data/training --epochs 3 --hf_token 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 --lr 0.0002 --merge_weights True --model_id meta-llama/Llama-2-13b-hf --per_device_train_batch_size 2\u001b[0m\n",
      "\u001b[34m2024-02-17 17:22:40,205 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_aoUeoCV...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: read).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/610 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 610/610 [00:00<00:00, 6.40MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 33.4k/33.4k [00:00<00:00, 218MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   0%|          | 41.9M/9.95G [00:00<00:24, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   1%|          | 83.9M/9.95G [00:00<00:29, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   1%|▏         | 126M/9.95G [00:00<00:26, 367MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   2%|▏         | 168M/9.95G [00:00<00:26, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   2%|▏         | 210M/9.95G [00:00<00:28, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   3%|▎         | 262M/9.95G [00:00<00:25, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   3%|▎         | 315M/9.95G [00:00<00:24, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   4%|▎         | 367M/9.95G [00:00<00:23, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   4%|▍         | 409M/9.95G [00:01<00:24, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   5%|▍         | 451M/9.95G [00:01<00:24, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   5%|▍         | 493M/9.95G [00:01<00:25, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   5%|▌         | 535M/9.95G [00:01<00:25, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   6%|▌         | 587M/9.95G [00:01<00:23, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   6%|▋         | 629M/9.95G [00:01<00:25, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   7%|▋         | 671M/9.95G [00:01<00:26, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   7%|▋         | 724M/9.95G [00:01<00:23, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   8%|▊         | 765M/9.95G [00:02<00:25, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   8%|▊         | 807M/9.95G [00:02<00:28, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   9%|▊         | 849M/9.95G [00:02<00:29, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   9%|▉         | 891M/9.95G [00:02<00:30, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:   9%|▉         | 933M/9.95G [00:02<00:30, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  10%|▉         | 975M/9.95G [00:02<00:29, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  10%|█         | 1.02G/9.95G [00:02<00:27, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  11%|█         | 1.06G/9.95G [00:03<00:26, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  11%|█         | 1.10G/9.95G [00:03<00:26, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  11%|█▏        | 1.14G/9.95G [00:03<00:32, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  12%|█▏        | 1.17G/9.95G [00:03<00:33, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  12%|█▏        | 1.22G/9.95G [00:03<00:30, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  13%|█▎        | 1.26G/9.95G [00:03<00:30, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  13%|█▎        | 1.29G/9.95G [00:03<00:31, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  13%|█▎        | 1.32G/9.95G [00:04<00:31, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  14%|█▎        | 1.36G/9.95G [00:04<00:28, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  14%|█▍        | 1.41G/9.95G [00:04<00:28, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  15%|█▍        | 1.45G/9.95G [00:04<00:26, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  15%|█▍        | 1.49G/9.95G [00:04<00:27, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  15%|█▌        | 1.53G/9.95G [00:04<00:26, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  16%|█▌        | 1.57G/9.95G [00:04<00:27, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  16%|█▌        | 1.60G/9.95G [00:04<00:27, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  17%|█▋        | 1.65G/9.95G [00:05<00:27, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  17%|█▋        | 1.68G/9.95G [00:05<00:27, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  17%|█▋        | 1.71G/9.95G [00:05<00:27, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  18%|█▊        | 1.75G/9.95G [00:05<00:25, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  18%|█▊        | 1.79G/9.95G [00:05<00:26, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  18%|█▊        | 1.82G/9.95G [00:05<00:27, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  19%|█▉        | 1.87G/9.95G [00:05<00:25, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  19%|█▉        | 1.92G/9.95G [00:05<00:22, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  20%|█▉        | 1.97G/9.95G [00:05<00:20, 391MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  20%|██        | 2.02G/9.95G [00:06<00:19, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  21%|██        | 2.07G/9.95G [00:06<00:19, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  21%|██        | 2.11G/9.95G [00:06<00:20, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  22%|██▏       | 2.15G/9.95G [00:06<00:20, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  22%|██▏       | 2.19G/9.95G [00:06<00:20, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  22%|██▏       | 2.23G/9.95G [00:06<00:19, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  23%|██▎       | 2.29G/9.95G [00:06<00:19, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  23%|██▎       | 2.33G/9.95G [00:06<00:20, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  24%|██▍       | 2.37G/9.95G [00:07<00:23, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  24%|██▍       | 2.41G/9.95G [00:07<00:22, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  25%|██▍       | 2.45G/9.95G [00:07<00:21, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  25%|██▌       | 2.51G/9.95G [00:07<00:20, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  26%|██▌       | 2.55G/9.95G [00:07<00:19, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  26%|██▌       | 2.59G/9.95G [00:07<00:20, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  26%|██▋       | 2.63G/9.95G [00:07<00:20, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  27%|██▋       | 2.68G/9.95G [00:07<00:20, 363MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  27%|██▋       | 2.73G/9.95G [00:08<00:20, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  28%|██▊       | 2.77G/9.95G [00:08<00:20, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  28%|██▊       | 2.81G/9.95G [00:08<00:19, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  29%|██▊       | 2.85G/9.95G [00:08<00:19, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  29%|██▉       | 2.89G/9.95G [00:08<00:19, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  30%|██▉       | 2.94G/9.95G [00:08<00:18, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  30%|██▉       | 2.98G/9.95G [00:08<00:18, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  30%|███       | 3.02G/9.95G [00:08<00:18, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  31%|███       | 3.06G/9.95G [00:08<00:18, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  31%|███       | 3.10G/9.95G [00:09<00:22, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  32%|███▏      | 3.15G/9.95G [00:09<00:21, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  32%|███▏      | 3.19G/9.95G [00:09<00:19, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  32%|███▏      | 3.23G/9.95G [00:09<00:19, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  33%|███▎      | 3.27G/9.95G [00:09<00:19, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  33%|███▎      | 3.31G/9.95G [00:09<00:18, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  34%|███▎      | 3.36G/9.95G [00:09<00:18, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  34%|███▍      | 3.40G/9.95G [00:09<00:18, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  35%|███▍      | 3.44G/9.95G [00:10<00:19, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  35%|███▍      | 3.48G/9.95G [00:10<00:21, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  35%|███▌      | 3.52G/9.95G [00:10<00:20, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  36%|███▌      | 3.57G/9.95G [00:10<00:19, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  36%|███▋      | 3.62G/9.95G [00:10<00:17, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  37%|███▋      | 3.67G/9.95G [00:10<00:15, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  37%|███▋      | 3.71G/9.95G [00:10<00:16, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  38%|███▊      | 3.75G/9.95G [00:10<00:16, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  38%|███▊      | 3.80G/9.95G [00:11<00:16, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  39%|███▊      | 3.84G/9.95G [00:11<00:16, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  39%|███▉      | 3.88G/9.95G [00:11<00:16, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  39%|███▉      | 3.92G/9.95G [00:11<00:15, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  40%|███▉      | 3.96G/9.95G [00:11<00:15, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  40%|████      | 4.02G/9.95G [00:11<00:14, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  41%|████      | 4.07G/9.95G [00:11<00:14, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  41%|████▏     | 4.11G/9.95G [00:11<00:14, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  42%|████▏     | 4.15G/9.95G [00:11<00:15, 385MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  42%|████▏     | 4.19G/9.95G [00:12<00:15, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  43%|████▎     | 4.24G/9.95G [00:12<00:15, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  43%|████▎     | 4.28G/9.95G [00:12<00:15, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  43%|████▎     | 4.32G/9.95G [00:12<00:15, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  44%|████▍     | 4.37G/9.95G [00:12<00:14, 391MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  44%|████▍     | 4.41G/9.95G [00:12<00:13, 396MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  45%|████▍     | 4.47G/9.95G [00:12<00:13, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  45%|████▌     | 4.51G/9.95G [00:12<00:14, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  46%|████▌     | 4.55G/9.95G [00:13<00:15, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  46%|████▌     | 4.59G/9.95G [00:13<00:16, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  47%|████▋     | 4.63G/9.95G [00:13<00:16, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  47%|████▋     | 4.68G/9.95G [00:13<00:18, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  47%|████▋     | 4.71G/9.95G [00:13<00:18, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  48%|████▊     | 4.75G/9.95G [00:13<00:17, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  48%|████▊     | 4.79G/9.95G [00:13<00:15, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  49%|████▊     | 4.83G/9.95G [00:14<00:15, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  49%|████▉     | 4.88G/9.95G [00:14<00:14, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  49%|████▉     | 4.92G/9.95G [00:14<00:13, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  50%|████▉     | 4.96G/9.95G [00:14<00:14, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  50%|█████     | 5.00G/9.95G [00:14<00:13, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  51%|█████     | 5.04G/9.95G [00:14<00:13, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  51%|█████     | 5.09G/9.95G [00:14<00:14, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  52%|█████▏    | 5.13G/9.95G [00:14<00:13, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  52%|█████▏    | 5.17G/9.95G [00:14<00:14, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  52%|█████▏    | 5.21G/9.95G [00:15<00:14, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  53%|█████▎    | 5.25G/9.95G [00:15<00:14, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  53%|█████▎    | 5.30G/9.95G [00:15<00:14, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  54%|█████▎    | 5.34G/9.95G [00:15<00:14, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  54%|█████▍    | 5.38G/9.95G [00:15<00:16, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  54%|█████▍    | 5.42G/9.95G [00:15<00:14, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  55%|█████▌    | 5.47G/9.95G [00:15<00:12, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  56%|█████▌    | 5.53G/9.95G [00:16<00:11, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  56%|█████▌    | 5.58G/9.95G [00:16<00:10, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  57%|█████▋    | 5.63G/9.95G [00:16<00:10, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  57%|█████▋    | 5.68G/9.95G [00:16<00:11, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  58%|█████▊    | 5.73G/9.95G [00:16<00:11, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  58%|█████▊    | 5.77G/9.95G [00:16<00:11, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  58%|█████▊    | 5.81G/9.95G [00:16<00:11, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  59%|█████▉    | 5.85G/9.95G [00:16<00:11, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  59%|█████▉    | 5.89G/9.95G [00:17<00:11, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  60%|█████▉    | 5.93G/9.95G [00:17<00:16, 240MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  60%|██████    | 5.98G/9.95G [00:17<00:14, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  60%|██████    | 6.02G/9.95G [00:17<00:14, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  61%|██████    | 6.07G/9.95G [00:17<00:12, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  61%|██████▏   | 6.11G/9.95G [00:17<00:11, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  62%|██████▏   | 6.16G/9.95G [00:17<00:11, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  62%|██████▏   | 6.20G/9.95G [00:18<00:11, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  63%|██████▎   | 6.24G/9.95G [00:18<00:11, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  63%|██████▎   | 6.28G/9.95G [00:18<00:11, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  64%|██████▎   | 6.32G/9.95G [00:18<00:12, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  64%|██████▍   | 6.36G/9.95G [00:18<00:12, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  64%|██████▍   | 6.40G/9.95G [00:18<00:12, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  65%|██████▍   | 6.43G/9.95G [00:18<00:14, 250MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  65%|██████▌   | 6.47G/9.95G [00:19<00:12, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  65%|██████▌   | 6.51G/9.95G [00:19<00:11, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  66%|██████▌   | 6.56G/9.95G [00:19<00:10, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  66%|██████▋   | 6.61G/9.95G [00:19<00:09, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  67%|██████▋   | 6.65G/9.95G [00:19<00:09, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  67%|██████▋   | 6.69G/9.95G [00:19<00:12, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  68%|██████▊   | 6.73G/9.95G [00:19<00:11, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  68%|██████▊   | 6.77G/9.95G [00:20<00:10, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  69%|██████▊   | 6.82G/9.95G [00:20<00:10, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  69%|██████▉   | 6.85G/9.95G [00:20<00:10, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  69%|██████▉   | 6.89G/9.95G [00:20<00:09, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  70%|██████▉   | 6.93G/9.95G [00:20<00:09, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  70%|███████   | 6.97G/9.95G [00:20<00:08, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  71%|███████   | 7.01G/9.95G [00:20<00:08, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  71%|███████   | 7.07G/9.95G [00:20<00:07, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  71%|███████▏  | 7.11G/9.95G [00:21<00:07, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  72%|███████▏  | 7.15G/9.95G [00:21<00:07, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  72%|███████▏  | 7.19G/9.95G [00:21<00:07, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  73%|███████▎  | 7.24G/9.95G [00:21<00:07, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  73%|███████▎  | 7.28G/9.95G [00:21<00:07, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  74%|███████▎  | 7.33G/9.95G [00:21<00:06, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  74%|███████▍  | 7.38G/9.95G [00:21<00:06, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  75%|███████▍  | 7.42G/9.95G [00:21<00:07, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  75%|███████▌  | 7.47G/9.95G [00:22<00:06, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  76%|███████▌  | 7.52G/9.95G [00:22<00:06, 391MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  76%|███████▌  | 7.56G/9.95G [00:22<00:06, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  76%|███████▋  | 7.60G/9.95G [00:22<00:06, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  77%|███████▋  | 7.64G/9.95G [00:22<00:05, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  77%|███████▋  | 7.70G/9.95G [00:22<00:05, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  78%|███████▊  | 7.74G/9.95G [00:22<00:06, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  78%|███████▊  | 7.78G/9.95G [00:22<00:06, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  79%|███████▊  | 7.82G/9.95G [00:23<00:06, 313MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  79%|███████▉  | 7.86G/9.95G [00:23<00:06, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  79%|███████▉  | 7.91G/9.95G [00:23<00:05, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  80%|███████▉  | 7.95G/9.95G [00:23<00:05, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  80%|████████  | 7.99G/9.95G [00:23<00:05, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  81%|████████  | 8.04G/9.95G [00:23<00:05, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  81%|████████▏ | 8.08G/9.95G [00:23<00:05, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  82%|████████▏ | 8.13G/9.95G [00:23<00:05, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  82%|████████▏ | 8.18G/9.95G [00:24<00:05, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  83%|████████▎ | 8.22G/9.95G [00:24<00:04, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  83%|████████▎ | 8.26G/9.95G [00:24<00:04, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  83%|████████▎ | 8.30G/9.95G [00:24<00:04, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  84%|████████▍ | 8.35G/9.95G [00:24<00:04, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  84%|████████▍ | 8.39G/9.95G [00:24<00:04, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  85%|████████▍ | 8.44G/9.95G [00:24<00:04, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  85%|████████▌ | 8.48G/9.95G [00:24<00:04, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  86%|████████▌ | 8.52G/9.95G [00:25<00:04, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  86%|████████▌ | 8.57G/9.95G [00:25<00:04, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  87%|████████▋ | 8.61G/9.95G [00:25<00:04, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  87%|████████▋ | 8.66G/9.95G [00:25<00:03, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  88%|████████▊ | 8.71G/9.95G [00:25<00:03, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  88%|████████▊ | 8.77G/9.95G [00:25<00:02, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  89%|████████▊ | 8.82G/9.95G [00:25<00:02, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  89%|████████▉ | 8.87G/9.95G [00:25<00:02, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  90%|████████▉ | 8.91G/9.95G [00:26<00:03, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  90%|█████████ | 8.95G/9.95G [00:26<00:03, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  90%|█████████ | 9.00G/9.95G [00:26<00:02, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  91%|█████████ | 9.04G/9.95G [00:26<00:02, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  91%|█████████▏| 9.08G/9.95G [00:26<00:02, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  92%|█████████▏| 9.12G/9.95G [00:26<00:02, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  92%|█████████▏| 9.16G/9.95G [00:26<00:02, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  92%|█████████▏| 9.20G/9.95G [00:27<00:02, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  93%|█████████▎| 9.23G/9.95G [00:27<00:02, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  93%|█████████▎| 9.26G/9.95G [00:27<00:03, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  94%|█████████▎| 9.31G/9.95G [00:27<00:02, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  94%|█████████▍| 9.35G/9.95G [00:27<00:02, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  94%|█████████▍| 9.38G/9.95G [00:27<00:02, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  95%|█████████▍| 9.43G/9.95G [00:27<00:01, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  95%|█████████▌| 9.47G/9.95G [00:28<00:01, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  96%|█████████▌| 9.51G/9.95G [00:28<00:01, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  96%|█████████▌| 9.55G/9.95G [00:28<00:01, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  97%|█████████▋| 9.60G/9.95G [00:28<00:01, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  97%|█████████▋| 9.65G/9.95G [00:28<00:00, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  97%|█████████▋| 9.69G/9.95G [00:28<00:00, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  98%|█████████▊| 9.73G/9.95G [00:28<00:00, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  98%|█████████▊| 9.77G/9.95G [00:28<00:00, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  99%|█████████▊| 9.81G/9.95G [00:29<00:00, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  99%|█████████▉| 9.86G/9.95G [00:29<00:00, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors:  99%|█████████▉| 9.90G/9.95G [00:29<00:00, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors: 100%|█████████▉| 9.94G/9.95G [00:29<00:00, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00003.safetensors: 100%|██████████| 9.95G/9.95G [00:29<00:00, 337MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  33%|███▎      | 1/3 [00:29<00:59, 29.56s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   0%|          | 31.5M/9.90G [00:00<00:41, 235MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   1%|          | 73.4M/9.90G [00:00<00:30, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   1%|          | 115M/9.90G [00:00<00:31, 310MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   2%|▏         | 157M/9.90G [00:00<00:34, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   2%|▏         | 199M/9.90G [00:00<00:34, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   2%|▏         | 231M/9.90G [00:00<00:34, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   3%|▎         | 262M/9.90G [00:00<00:34, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   3%|▎         | 294M/9.90G [00:01<00:38, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   3%|▎         | 325M/9.90G [00:01<00:39, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   4%|▎         | 367M/9.90G [00:01<00:34, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   4%|▍         | 398M/9.90G [00:01<00:38, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   4%|▍         | 440M/9.90G [00:01<00:34, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   5%|▍         | 472M/9.90G [00:01<00:33, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   5%|▌         | 503M/9.90G [00:01<00:36, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   5%|▌         | 535M/9.90G [00:01<00:35, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   6%|▌         | 566M/9.90G [00:02<00:34, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   6%|▌         | 619M/9.90G [00:02<00:29, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   7%|▋         | 650M/9.90G [00:02<00:31, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   7%|▋         | 682M/9.90G [00:02<00:32, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   7%|▋         | 724M/9.90G [00:02<00:30, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   8%|▊         | 765M/9.90G [00:02<00:28, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   8%|▊         | 807M/9.90G [00:02<00:28, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   9%|▊         | 849M/9.90G [00:02<00:28, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   9%|▉         | 891M/9.90G [00:03<00:29, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:   9%|▉         | 923M/9.90G [00:03<00:30, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  10%|▉         | 954M/9.90G [00:03<00:31, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  10%|▉         | 986M/9.90G [00:03<00:36, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  10%|█         | 1.02G/9.90G [00:03<00:34, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  11%|█         | 1.05G/9.90G [00:03<00:32, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  11%|█         | 1.09G/9.90G [00:03<00:29, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  11%|█▏        | 1.13G/9.90G [00:03<00:26, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  12%|█▏        | 1.17G/9.90G [00:04<00:29, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  12%|█▏        | 1.21G/9.90G [00:04<00:32, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  13%|█▎        | 1.25G/9.90G [00:04<00:30, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  13%|█▎        | 1.29G/9.90G [00:04<00:28, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  14%|█▎        | 1.34G/9.90G [00:04<00:25, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  14%|█▍        | 1.38G/9.90G [00:04<00:24, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  14%|█▍        | 1.43G/9.90G [00:04<00:24, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  15%|█▍        | 1.47G/9.90G [00:05<00:27, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  15%|█▌        | 1.51G/9.90G [00:05<00:26, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  16%|█▌        | 1.55G/9.90G [00:05<00:26, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  16%|█▌        | 1.59G/9.90G [00:05<00:25, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  17%|█▋        | 1.64G/9.90G [00:05<00:31, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  17%|█▋        | 1.67G/9.90G [00:05<00:33, 247MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  17%|█▋        | 1.70G/9.90G [00:05<00:33, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  17%|█▋        | 1.73G/9.90G [00:06<00:33, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  18%|█▊        | 1.76G/9.90G [00:06<00:32, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  18%|█▊        | 1.79G/9.90G [00:06<00:31, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  18%|█▊        | 1.82G/9.90G [00:06<00:34, 235MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  19%|█▊        | 1.86G/9.90G [00:06<00:34, 231MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  19%|█▉        | 1.89G/9.90G [00:06<00:37, 214MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  19%|█▉        | 1.92G/9.90G [00:06<00:38, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  20%|█▉        | 1.95G/9.90G [00:07<00:36, 218MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  20%|██        | 1.98G/9.90G [00:07<00:37, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  20%|██        | 2.01G/9.90G [00:07<00:40, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  21%|██        | 2.06G/9.90G [00:07<00:34, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  21%|██        | 2.10G/9.90G [00:07<00:29, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  22%|██▏       | 2.15G/9.90G [00:07<00:25, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  22%|██▏       | 2.19G/9.90G [00:08<00:34, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  23%|██▎       | 2.24G/9.90G [00:08<00:28, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  23%|██▎       | 2.29G/9.90G [00:08<00:28, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  24%|██▎       | 2.33G/9.90G [00:08<00:26, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  24%|██▍       | 2.37G/9.90G [00:08<00:25, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  24%|██▍       | 2.41G/9.90G [00:08<00:31, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  25%|██▍       | 2.45G/9.90G [00:08<00:27, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  25%|██▌       | 2.49G/9.90G [00:09<00:27, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  26%|██▌       | 2.53G/9.90G [00:09<00:25, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  26%|██▌       | 2.57G/9.90G [00:09<00:24, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  26%|██▋       | 2.60G/9.90G [00:09<00:24, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  27%|██▋       | 2.63G/9.90G [00:09<00:27, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  27%|██▋       | 2.66G/9.90G [00:09<00:35, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  27%|██▋       | 2.69G/9.90G [00:10<00:36, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  28%|██▊       | 2.73G/9.90G [00:10<00:40, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  28%|██▊       | 2.78G/9.90G [00:10<00:30, 236MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  28%|██▊       | 2.81G/9.90G [00:10<00:28, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  29%|██▉       | 2.85G/9.90G [00:10<00:26, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  29%|██▉       | 2.88G/9.90G [00:10<00:26, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  30%|██▉       | 2.93G/9.90G [00:10<00:23, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  30%|██▉       | 2.97G/9.90G [00:10<00:22, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  30%|███       | 3.01G/9.90G [00:11<00:20, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  31%|███       | 3.05G/9.90G [00:11<00:20, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  31%|███       | 3.09G/9.90G [00:11<00:20, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  32%|███▏      | 3.14G/9.90G [00:11<00:21, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  32%|███▏      | 3.18G/9.90G [00:11<00:20, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  33%|███▎      | 3.22G/9.90G [00:11<00:20, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  33%|███▎      | 3.26G/9.90G [00:11<00:20, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  33%|███▎      | 3.30G/9.90G [00:11<00:19, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  34%|███▍      | 3.34G/9.90G [00:12<00:18, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  34%|███▍      | 3.39G/9.90G [00:12<00:18, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  35%|███▍      | 3.43G/9.90G [00:12<00:18, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  35%|███▌      | 3.47G/9.90G [00:12<00:21, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  35%|███▌      | 3.51G/9.90G [00:12<00:20, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  36%|███▌      | 3.55G/9.90G [00:12<00:20, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  36%|███▌      | 3.59G/9.90G [00:12<00:22, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  37%|███▋      | 3.62G/9.90G [00:13<00:25, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  37%|███▋      | 3.66G/9.90G [00:13<00:23, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  37%|███▋      | 3.69G/9.90G [00:13<00:23, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  38%|███▊      | 3.73G/9.90G [00:13<00:20, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  38%|███▊      | 3.76G/9.90G [00:13<00:20, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  38%|███▊      | 3.80G/9.90G [00:13<00:22, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  39%|███▊      | 3.84G/9.90G [00:13<00:20, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  39%|███▉      | 3.87G/9.90G [00:13<00:20, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  40%|███▉      | 3.92G/9.90G [00:14<00:17, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  40%|████      | 3.96G/9.90G [00:14<00:17, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  40%|████      | 4.01G/9.90G [00:14<00:17, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  41%|████      | 4.05G/9.90G [00:14<00:17, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  41%|████▏     | 4.09G/9.90G [00:14<00:18, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  42%|████▏     | 4.13G/9.90G [00:14<00:17, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  42%|████▏     | 4.17G/9.90G [00:14<00:18, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  42%|████▏     | 4.20G/9.90G [00:14<00:19, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  43%|████▎     | 4.25G/9.90G [00:15<00:18, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  43%|████▎     | 4.29G/9.90G [00:15<00:17, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  44%|████▎     | 4.33G/9.90G [00:15<00:18, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  44%|████▍     | 4.36G/9.90G [00:15<00:18, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  44%|████▍     | 4.40G/9.90G [00:15<00:17, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  45%|████▍     | 4.45G/9.90G [00:15<00:17, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  45%|████▌     | 4.49G/9.90G [00:15<00:18, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  46%|████▌     | 4.52G/9.90G [00:15<00:18, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  46%|████▌     | 4.56G/9.90G [00:16<00:16, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  46%|████▋     | 4.60G/9.90G [00:16<00:15, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  47%|████▋     | 4.65G/9.90G [00:16<00:15, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  47%|████▋     | 4.70G/9.90G [00:16<00:14, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  48%|████▊     | 4.74G/9.90G [00:16<00:14, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  48%|████▊     | 4.78G/9.90G [00:16<00:16, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  49%|████▊     | 4.82G/9.90G [00:16<00:16, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  49%|████▉     | 4.87G/9.90G [00:17<00:15, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  50%|████▉     | 4.91G/9.90G [00:17<00:15, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  50%|████▉     | 4.95G/9.90G [00:17<00:15, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  51%|█████     | 5.00G/9.90G [00:17<00:14, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  51%|█████     | 5.04G/9.90G [00:17<00:15, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  51%|█████▏    | 5.09G/9.90G [00:17<00:15, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  52%|█████▏    | 5.13G/9.90G [00:17<00:16, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  52%|█████▏    | 5.16G/9.90G [00:17<00:17, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  52%|█████▏    | 5.19G/9.90G [00:18<00:23, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  53%|█████▎    | 5.23G/9.90G [00:18<00:19, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  53%|█████▎    | 5.27G/9.90G [00:18<00:17, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  54%|█████▍    | 5.33G/9.90G [00:18<00:14, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  54%|█████▍    | 5.37G/9.90G [00:18<00:13, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  55%|█████▍    | 5.41G/9.90G [00:18<00:13, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  55%|█████▌    | 5.45G/9.90G [00:18<00:12, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  56%|█████▌    | 5.51G/9.90G [00:19<00:12, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  56%|█████▌    | 5.55G/9.90G [00:19<00:14, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  56%|█████▋    | 5.59G/9.90G [00:19<00:14, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  57%|█████▋    | 5.63G/9.90G [00:19<00:13, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  57%|█████▋    | 5.67G/9.90G [00:19<00:12, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  58%|█████▊    | 5.71G/9.90G [00:19<00:12, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  58%|█████▊    | 5.76G/9.90G [00:19<00:12, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  59%|█████▊    | 5.80G/9.90G [00:20<00:12, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  59%|█████▉    | 5.84G/9.90G [00:20<00:12, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  60%|█████▉    | 5.89G/9.90G [00:20<00:11, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  60%|█████▉    | 5.93G/9.90G [00:20<00:14, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  60%|██████    | 5.97G/9.90G [00:20<00:14, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  61%|██████    | 6.01G/9.90G [00:20<00:13, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  61%|██████    | 6.05G/9.90G [00:20<00:13, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  62%|██████▏   | 6.09G/9.90G [00:20<00:12, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  62%|██████▏   | 6.13G/9.90G [00:21<00:11, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  62%|██████▏   | 6.19G/9.90G [00:21<00:10, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  63%|██████▎   | 6.23G/9.90G [00:21<00:11, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  63%|██████▎   | 6.27G/9.90G [00:21<00:13, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  64%|██████▎   | 6.31G/9.90G [00:21<00:11, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  64%|██████▍   | 6.35G/9.90G [00:21<00:10, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  65%|██████▍   | 6.40G/9.90G [00:21<00:10, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  65%|██████▌   | 6.44G/9.90G [00:22<00:10, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  65%|██████▌   | 6.48G/9.90G [00:22<00:11, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  66%|██████▌   | 6.52G/9.90G [00:22<00:10, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  66%|██████▋   | 6.56G/9.90G [00:22<00:10, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  67%|██████▋   | 6.61G/9.90G [00:22<00:10, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  67%|██████▋   | 6.65G/9.90G [00:22<00:10, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  68%|██████▊   | 6.70G/9.90G [00:22<00:09, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  68%|██████▊   | 6.75G/9.90G [00:22<00:08, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  69%|██████▊   | 6.81G/9.90G [00:23<00:08, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  69%|██████▉   | 6.86G/9.90G [00:23<00:07, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  70%|██████▉   | 6.90G/9.90G [00:23<00:08, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  70%|███████   | 6.94G/9.90G [00:23<00:07, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  71%|███████   | 6.98G/9.90G [00:23<00:08, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  71%|███████   | 7.04G/9.90G [00:23<00:08, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  71%|███████▏  | 7.08G/9.90G [00:23<00:07, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  72%|███████▏  | 7.12G/9.90G [00:24<00:07, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  72%|███████▏  | 7.16G/9.90G [00:24<00:08, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  73%|███████▎  | 7.20G/9.90G [00:24<00:08, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  73%|███████▎  | 7.25G/9.90G [00:24<00:08, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  74%|███████▎  | 7.29G/9.90G [00:24<00:08, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  74%|███████▍  | 7.33G/9.90G [00:24<00:07, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  74%|███████▍  | 7.37G/9.90G [00:24<00:07, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  75%|███████▍  | 7.41G/9.90G [00:24<00:07, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  75%|███████▌  | 7.46G/9.90G [00:25<00:06, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  76%|███████▌  | 7.50G/9.90G [00:25<00:08, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  76%|███████▌  | 7.54G/9.90G [00:25<00:07, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  77%|███████▋  | 7.58G/9.90G [00:25<00:07, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  77%|███████▋  | 7.62G/9.90G [00:25<00:08, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  77%|███████▋  | 7.65G/9.90G [00:25<00:07, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  78%|███████▊  | 7.70G/9.90G [00:25<00:07, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  78%|███████▊  | 7.74G/9.90G [00:25<00:06, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  79%|███████▊  | 7.78G/9.90G [00:26<00:06, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  79%|███████▉  | 7.82G/9.90G [00:26<00:06, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  79%|███████▉  | 7.85G/9.90G [00:26<00:07, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  80%|███████▉  | 7.89G/9.90G [00:26<00:07, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  80%|████████  | 7.93G/9.90G [00:26<00:06, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  80%|████████  | 7.97G/9.90G [00:26<00:06, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  81%|████████  | 8.00G/9.90G [00:26<00:06, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  81%|████████  | 8.04G/9.90G [00:26<00:05, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  82%|████████▏ | 8.08G/9.90G [00:27<00:05, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  82%|████████▏ | 8.14G/9.90G [00:27<00:04, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  83%|████████▎ | 8.18G/9.90G [00:27<00:05, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  83%|████████▎ | 8.22G/9.90G [00:27<00:05, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  83%|████████▎ | 8.25G/9.90G [00:27<00:06, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  84%|████████▎ | 8.29G/9.90G [00:27<00:05, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  84%|████████▍ | 8.33G/9.90G [00:27<00:05, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  84%|████████▍ | 8.36G/9.90G [00:28<00:05, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  85%|████████▍ | 8.39G/9.90G [00:28<00:05, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  85%|████████▌ | 8.42G/9.90G [00:28<00:07, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  85%|████████▌ | 8.46G/9.90G [00:28<00:06, 220MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  86%|████████▌ | 8.49G/9.90G [00:28<00:06, 229MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  86%|████████▌ | 8.54G/9.90G [00:28<00:05, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  87%|████████▋ | 8.58G/9.90G [00:28<00:04, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  87%|████████▋ | 8.62G/9.90G [00:29<00:04, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  87%|████████▋ | 8.65G/9.90G [00:29<00:04, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  88%|████████▊ | 8.68G/9.90G [00:29<00:04, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  88%|████████▊ | 8.71G/9.90G [00:29<00:04, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  88%|████████▊ | 8.76G/9.90G [00:29<00:03, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  89%|████████▊ | 8.79G/9.90G [00:29<00:03, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  89%|████████▉ | 8.82G/9.90G [00:29<00:03, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  89%|████████▉ | 8.86G/9.90G [00:29<00:03, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  90%|████████▉ | 8.90G/9.90G [00:30<00:02, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  90%|█████████ | 8.94G/9.90G [00:30<00:02, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  91%|█████████ | 8.99G/9.90G [00:30<00:02, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  91%|█████████ | 9.03G/9.90G [00:30<00:02, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  92%|█████████▏| 9.07G/9.90G [00:30<00:03, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  92%|█████████▏| 9.11G/9.90G [00:30<00:02, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  92%|█████████▏| 9.15G/9.90G [00:30<00:02, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  93%|█████████▎| 9.21G/9.90G [00:31<00:02, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  93%|█████████▎| 9.25G/9.90G [00:31<00:02, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  94%|█████████▍| 9.29G/9.90G [00:31<00:02, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  94%|█████████▍| 9.32G/9.90G [00:31<00:02, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  95%|█████████▍| 9.36G/9.90G [00:31<00:01, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  95%|█████████▍| 9.40G/9.90G [00:31<00:01, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  95%|█████████▌| 9.44G/9.90G [00:31<00:01, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  96%|█████████▌| 9.48G/9.90G [00:32<00:01, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  96%|█████████▌| 9.52G/9.90G [00:32<00:01, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  97%|█████████▋| 9.56G/9.90G [00:32<00:01, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  97%|█████████▋| 9.60G/9.90G [00:32<00:01, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  97%|█████████▋| 9.64G/9.90G [00:32<00:00, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  98%|█████████▊| 9.67G/9.90G [00:32<00:00, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  98%|█████████▊| 9.71G/9.90G [00:32<00:00, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  98%|█████████▊| 9.74G/9.90G [00:32<00:00, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  99%|█████████▉| 9.78G/9.90G [00:33<00:00, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors:  99%|█████████▉| 9.83G/9.90G [00:33<00:00, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors: 100%|█████████▉| 9.86G/9.90G [00:33<00:00, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors: 100%|█████████▉| 9.89G/9.90G [00:33<00:00, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00003.safetensors: 100%|██████████| 9.90G/9.90G [00:33<00:00, 295MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  67%|██████▋   | 2/3 [01:03<00:31, 32.00s/it]\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   1%|          | 41.9M/6.18G [00:00<00:17, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   1%|▏         | 83.9M/6.18G [00:00<00:16, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   2%|▏         | 126M/6.18G [00:00<00:15, 380MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   3%|▎         | 168M/6.18G [00:00<00:17, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   3%|▎         | 210M/6.18G [00:00<00:17, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   4%|▍         | 252M/6.18G [00:00<00:16, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   5%|▍         | 294M/6.18G [00:00<00:16, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   5%|▌         | 336M/6.18G [00:00<00:18, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   6%|▌         | 377M/6.18G [00:01<00:20, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   7%|▋         | 409M/6.18G [00:01<00:23, 247MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   7%|▋         | 440M/6.18G [00:01<00:24, 237MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   8%|▊         | 493M/6.18G [00:01<00:19, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   9%|▊         | 535M/6.18G [00:01<00:20, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:   9%|▉         | 566M/6.18G [00:01<00:20, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  10%|▉         | 608M/6.18G [00:02<00:18, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  11%|█         | 650M/6.18G [00:02<00:18, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  11%|█         | 682M/6.18G [00:02<00:18, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  12%|█▏        | 713M/6.18G [00:02<00:18, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  12%|█▏        | 744M/6.18G [00:02<00:18, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  13%|█▎        | 786M/6.18G [00:02<00:17, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  13%|█▎        | 818M/6.18G [00:02<00:18, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  14%|█▍        | 870M/6.18G [00:02<00:15, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  15%|█▍        | 912M/6.18G [00:02<00:16, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  15%|█▌        | 954M/6.18G [00:03<00:16, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  16%|█▌        | 996M/6.18G [00:03<00:15, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  17%|█▋        | 1.04G/6.18G [00:03<00:17, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  17%|█▋        | 1.07G/6.18G [00:03<00:17, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  18%|█▊        | 1.11G/6.18G [00:03<00:18, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  18%|█▊        | 1.14G/6.18G [00:03<00:19, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  19%|█▉        | 1.17G/6.18G [00:03<00:19, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  20%|█▉        | 1.21G/6.18G [00:04<00:18, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  20%|██        | 1.26G/6.18G [00:04<00:15, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  21%|██        | 1.30G/6.18G [00:04<00:15, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  22%|██▏       | 1.34G/6.18G [00:04<00:15, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  22%|██▏       | 1.38G/6.18G [00:04<00:15, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  23%|██▎       | 1.42G/6.18G [00:04<00:17, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  23%|██▎       | 1.45G/6.18G [00:04<00:21, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  24%|██▍       | 1.50G/6.18G [00:05<00:18, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  25%|██▍       | 1.53G/6.18G [00:05<00:17, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  25%|██▌       | 1.56G/6.18G [00:05<00:17, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  26%|██▌       | 1.59G/6.18G [00:05<00:16, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  26%|██▋       | 1.64G/6.18G [00:05<00:15, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  27%|██▋       | 1.67G/6.18G [00:05<00:15, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  27%|██▋       | 1.70G/6.18G [00:05<00:16, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  28%|██▊       | 1.74G/6.18G [00:05<00:15, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  29%|██▊       | 1.77G/6.18G [00:06<00:15, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  29%|██▉       | 1.80G/6.18G [00:06<00:16, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  30%|██▉       | 1.85G/6.18G [00:06<00:15, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  30%|███       | 1.88G/6.18G [00:06<00:19, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  31%|███       | 1.91G/6.18G [00:06<00:20, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  31%|███▏      | 1.94G/6.18G [00:06<00:18, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  32%|███▏      | 1.97G/6.18G [00:06<00:17, 237MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  33%|███▎      | 2.01G/6.18G [00:07<00:15, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  33%|███▎      | 2.04G/6.18G [00:07<00:15, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  34%|███▍      | 2.09G/6.18G [00:07<00:14, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  34%|███▍      | 2.12G/6.18G [00:07<00:14, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  35%|███▍      | 2.15G/6.18G [00:07<00:14, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  35%|███▌      | 2.18G/6.18G [00:07<00:14, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  36%|███▌      | 2.21G/6.18G [00:07<00:16, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  36%|███▋      | 2.24G/6.18G [00:08<00:18, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  37%|███▋      | 2.28G/6.18G [00:08<00:20, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  37%|███▋      | 2.30G/6.18G [00:08<00:23, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  38%|███▊      | 2.33G/6.18G [00:08<00:20, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  38%|███▊      | 2.36G/6.18G [00:08<00:18, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  39%|███▉      | 2.40G/6.18G [00:08<00:16, 232MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  40%|███▉      | 2.44G/6.18G [00:08<00:14, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  40%|████      | 2.47G/6.18G [00:09<00:14, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  41%|████      | 2.51G/6.18G [00:09<00:13, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  41%|████      | 2.54G/6.18G [00:09<00:13, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  42%|████▏     | 2.57G/6.18G [00:09<00:13, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  42%|████▏     | 2.60G/6.18G [00:09<00:12, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  43%|████▎     | 2.64G/6.18G [00:09<00:11, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  43%|████▎     | 2.67G/6.18G [00:09<00:12, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  44%|████▍     | 2.72G/6.18G [00:09<00:11, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  45%|████▍     | 2.76G/6.18G [00:09<00:10, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  45%|████▌     | 2.80G/6.18G [00:10<00:10, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  46%|████▌     | 2.83G/6.18G [00:10<00:11, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  46%|████▋     | 2.86G/6.18G [00:10<00:11, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  47%|████▋     | 2.89G/6.18G [00:10<00:12, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  47%|████▋     | 2.93G/6.18G [00:10<00:12, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  48%|████▊     | 2.96G/6.18G [00:10<00:12, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  48%|████▊     | 2.99G/6.18G [00:10<00:12, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  49%|████▉     | 3.03G/6.18G [00:11<00:11, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  50%|████▉     | 3.06G/6.18G [00:11<00:11, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  50%|█████     | 3.10G/6.18G [00:11<00:10, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  51%|█████     | 3.14G/6.18G [00:11<00:10, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  51%|█████     | 3.17G/6.18G [00:11<00:11, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  52%|█████▏    | 3.20G/6.18G [00:11<00:11, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  52%|█████▏    | 3.23G/6.18G [00:11<00:11, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  53%|█████▎    | 3.26G/6.18G [00:11<00:10, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  53%|█████▎    | 3.30G/6.18G [00:12<00:10, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  54%|█████▍    | 3.33G/6.18G [00:12<00:11, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  55%|█████▍    | 3.38G/6.18G [00:12<00:09, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  55%|█████▌    | 3.41G/6.18G [00:12<00:09, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  56%|█████▌    | 3.44G/6.18G [00:12<00:11, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  56%|█████▋    | 3.48G/6.18G [00:12<00:09, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  57%|█████▋    | 3.51G/6.18G [00:12<00:09, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  57%|█████▋    | 3.54G/6.18G [00:12<00:09, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  58%|█████▊    | 3.58G/6.18G [00:13<00:09, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  58%|█████▊    | 3.61G/6.18G [00:13<00:10, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  59%|█████▉    | 3.65G/6.18G [00:13<00:09, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  60%|█████▉    | 3.69G/6.18G [00:13<00:08, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  60%|██████    | 3.73G/6.18G [00:13<00:07, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  61%|██████    | 3.77G/6.18G [00:13<00:07, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  62%|██████▏   | 3.82G/6.18G [00:13<00:07, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  62%|██████▏   | 3.85G/6.18G [00:13<00:07, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  63%|██████▎   | 3.89G/6.18G [00:14<00:07, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  64%|██████▎   | 3.93G/6.18G [00:14<00:06, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  64%|██████▍   | 3.97G/6.18G [00:14<00:06, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  65%|██████▍   | 4.02G/6.18G [00:14<00:06, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  66%|██████▌   | 4.06G/6.18G [00:14<00:06, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  66%|██████▋   | 4.10G/6.18G [00:14<00:06, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  67%|██████▋   | 4.14G/6.18G [00:14<00:06, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  68%|██████▊   | 4.18G/6.18G [00:15<00:09, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  68%|██████▊   | 4.23G/6.18G [00:15<00:08, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  69%|██████▉   | 4.28G/6.18G [00:15<00:07, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  70%|██████▉   | 4.32G/6.18G [00:15<00:07, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  70%|███████   | 4.35G/6.18G [00:15<00:07, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  71%|███████   | 4.39G/6.18G [00:15<00:06, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  72%|███████▏  | 4.44G/6.18G [00:15<00:06, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  72%|███████▏  | 4.48G/6.18G [00:16<00:05, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  73%|███████▎  | 4.52G/6.18G [00:16<00:05, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  74%|███████▎  | 4.55G/6.18G [00:16<00:05, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  74%|███████▍  | 4.58G/6.18G [00:16<00:06, 260MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  75%|███████▍  | 4.62G/6.18G [00:16<00:05, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  76%|███████▌  | 4.67G/6.18G [00:16<00:04, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  76%|███████▌  | 4.71G/6.18G [00:16<00:04, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  77%|███████▋  | 4.76G/6.18G [00:17<00:04, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  78%|███████▊  | 4.80G/6.18G [00:17<00:04, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  78%|███████▊  | 4.84G/6.18G [00:17<00:04, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  79%|███████▉  | 4.89G/6.18G [00:17<00:04, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  80%|███████▉  | 4.92G/6.18G [00:17<00:04, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  80%|████████  | 4.96G/6.18G [00:17<00:04, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  81%|████████  | 4.99G/6.18G [00:17<00:03, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  81%|████████▏ | 5.03G/6.18G [00:17<00:03, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  82%|████████▏ | 5.08G/6.18G [00:18<00:03, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  83%|████████▎ | 5.12G/6.18G [00:18<00:03, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  83%|████████▎ | 5.16G/6.18G [00:18<00:03, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  84%|████████▍ | 5.20G/6.18G [00:18<00:03, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  85%|████████▍ | 5.24G/6.18G [00:18<00:02, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  86%|████████▌ | 5.28G/6.18G [00:18<00:02, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  86%|████████▌ | 5.33G/6.18G [00:18<00:02, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  87%|████████▋ | 5.37G/6.18G [00:18<00:02, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  88%|████████▊ | 5.41G/6.18G [00:19<00:02, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  88%|████████▊ | 5.45G/6.18G [00:19<00:02, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  89%|████████▉ | 5.48G/6.18G [00:19<00:02, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  89%|████████▉ | 5.52G/6.18G [00:19<00:02, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  90%|████████▉ | 5.56G/6.18G [00:19<00:02, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  91%|█████████ | 5.60G/6.18G [00:19<00:01, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  91%|█████████ | 5.63G/6.18G [00:19<00:01, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  92%|█████████▏| 5.66G/6.18G [00:20<00:01, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  92%|█████████▏| 5.69G/6.18G [00:20<00:01, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  93%|█████████▎| 5.73G/6.18G [00:20<00:01, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  93%|█████████▎| 5.77G/6.18G [00:20<00:01, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  94%|█████████▍| 5.80G/6.18G [00:20<00:01, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  95%|█████████▍| 5.84G/6.18G [00:20<00:01, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  95%|█████████▌| 5.87G/6.18G [00:20<00:01, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  96%|█████████▌| 5.90G/6.18G [00:20<00:00, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  96%|█████████▌| 5.95G/6.18G [00:20<00:00, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  97%|█████████▋| 5.99G/6.18G [00:21<00:00, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  98%|█████████▊| 6.03G/6.18G [00:21<00:00, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  98%|█████████▊| 6.08G/6.18G [00:21<00:00, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors:  99%|█████████▉| 6.12G/6.18G [00:21<00:00, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors: 100%|█████████▉| 6.17G/6.18G [00:21<00:00, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00003-of-00003.safetensors: 100%|██████████| 6.18G/6.18G [00:21<00:00, 285MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 3/3 [01:25<00:00, 27.35s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 3/3 [01:25<00:00, 28.36s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 188/188 [00:00<00:00, 2.27MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['k_proj', 'q_proj', 'v_proj', 'up_proj', 'gate_proj', 'down_proj', 'o_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 250,347,520 || all params: 6,922,327,040 || trainable%: 3.6165225733108386\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 0/318 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1/318 [00:13<1:10:41, 13.38s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 2/318 [00:26<1:09:51, 13.26s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 3/318 [00:39<1:09:26, 13.23s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 4/318 [00:52<1:09:08, 13.21s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 5/318 [01:06<1:08:51, 13.20s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 6/318 [01:19<1:08:36, 13.19s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7/318 [01:32<1:08:22, 13.19s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 8/318 [01:45<1:08:08, 13.19s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 9/318 [01:58<1:07:54, 13.19s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 10/318 [02:12<1:07:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.498, 'learning_rate': 0.00019371069182389937, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m3%|▎         | 10/318 [02:12<1:07:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 11/318 [02:25<1:07:27, 13.18s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 12/318 [02:38<1:07:14, 13.18s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 13/318 [02:51<1:07:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 14/318 [03:04<1:06:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 15/318 [03:17<1:06:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 16/318 [03:31<1:06:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 17/318 [03:44<1:06:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 18/318 [03:57<1:05:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 19/318 [04:10<1:05:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 20/318 [04:23<1:05:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.4068, 'learning_rate': 0.00018742138364779876, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m6%|▋         | 20/318 [04:23<1:05:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 21/318 [04:37<1:05:15, 13.18s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 22/318 [04:50<1:05:02, 13.18s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 23/318 [05:03<1:04:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 24/318 [05:16<1:04:35, 13.18s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 25/318 [05:29<1:04:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 26/318 [05:42<1:04:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 27/318 [05:56<1:03:56, 13.18s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 28/318 [06:09<1:03:43, 13.18s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 29/318 [06:22<1:03:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 30/318 [06:35<1:03:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3691, 'learning_rate': 0.00018113207547169812, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m9%|▉         | 30/318 [06:35<1:03:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 31/318 [06:48<1:03:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 32/318 [07:02<1:02:50, 13.18s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 33/318 [07:15<1:02:37, 13.18s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 34/318 [07:28<1:02:23, 13.18s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 35/318 [07:41<1:02:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 36/318 [07:54<1:01:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 37/318 [08:07<1:01:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 38/318 [08:21<1:01:31, 13.18s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 39/318 [08:34<1:01:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 40/318 [08:47<1:01:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3621, 'learning_rate': 0.0001748427672955975, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 40/318 [08:47<1:01:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 41/318 [09:00<1:00:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 42/318 [09:13<1:00:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 43/318 [09:27<1:00:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 44/318 [09:40<1:00:12, 13.18s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 45/318 [09:53<59:59, 13.18s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 46/318 [10:06<59:46, 13.18s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 47/318 [10:19<59:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 48/318 [10:32<59:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 49/318 [10:46<59:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 50/318 [10:59<58:53, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3016, 'learning_rate': 0.00016855345911949687, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 50/318 [10:59<58:53, 13.18s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 51/318 [11:12<58:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 52/318 [11:25<58:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 53/318 [11:38<58:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 54/318 [11:52<58:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 55/318 [12:05<57:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 56/318 [12:18<57:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 57/318 [12:31<57:21, 13.18s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 58/318 [12:44<57:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 59/318 [12:58<56:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 60/318 [13:11<56:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3384, 'learning_rate': 0.00016226415094339625, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 60/318 [13:11<56:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 61/318 [13:24<56:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 62/318 [13:37<56:14, 13.18s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 63/318 [13:50<56:01, 13.18s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 64/318 [14:03<55:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 65/318 [14:17<55:35, 13.18s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 66/318 [14:30<55:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 67/318 [14:43<55:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 68/318 [14:56<54:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 69/318 [15:09<54:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 70/318 [15:23<54:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3168, 'learning_rate': 0.00015597484276729561, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 70/318 [15:23<54:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 71/318 [15:36<54:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 72/318 [15:49<54:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 73/318 [16:02<53:50, 13.18s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 74/318 [16:15<53:37, 13.18s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 75/318 [16:28<53:24, 13.19s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 76/318 [16:42<53:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 77/318 [16:55<52:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 78/318 [17:08<52:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 79/318 [17:21<52:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 80/318 [17:34<52:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3198, 'learning_rate': 0.00014968553459119498, 'epoch': 0.75}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 80/318 [17:34<52:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 81/318 [17:48<52:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 82/318 [18:01<51:51, 13.19s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 83/318 [18:14<51:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 84/318 [18:27<51:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 85/318 [18:40<51:11, 13.18s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 86/318 [18:53<50:58, 13.18s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 87/318 [19:07<50:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 88/318 [19:20<50:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 89/318 [19:33<50:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 90/318 [19:46<50:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2441, 'learning_rate': 0.00014339622641509434, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 90/318 [19:46<50:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 91/318 [19:59<49:52, 13.18s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 92/318 [20:13<49:39, 13.18s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 93/318 [20:26<49:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 94/318 [20:39<49:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 95/318 [20:52<48:59, 13.18s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 96/318 [21:05<48:46, 13.18s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 97/318 [21:18<48:33, 13.18s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 98/318 [21:32<48:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 99/318 [21:45<48:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 100/318 [21:58<47:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2567, 'learning_rate': 0.0001371069182389937, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m31%|███▏      | 100/318 [21:58<47:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 101/318 [22:11<47:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 102/318 [22:24<47:27, 13.18s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 103/318 [22:38<47:14, 13.18s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 104/318 [22:51<47:01, 13.18s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 105/318 [23:04<46:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 106/318 [23:17<46:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 107/318 [23:30<46:21, 13.18s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 108/318 [23:44<46:08, 13.18s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 109/318 [23:57<45:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 110/318 [24:10<45:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2349, 'learning_rate': 0.00013081761006289308, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 110/318 [24:10<45:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 111/318 [24:23<45:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 112/318 [24:36<45:15, 13.18s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 113/318 [24:49<45:02, 13.18s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 114/318 [25:03<44:49, 13.18s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 115/318 [25:16<44:36, 13.18s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 116/318 [25:29<44:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 117/318 [25:42<44:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 118/318 [25:55<43:56, 13.18s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 119/318 [26:09<43:43, 13.18s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 120/318 [26:22<43:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1961, 'learning_rate': 0.00012452830188679244, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 120/318 [26:22<43:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 121/318 [26:35<43:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 122/318 [26:48<43:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 123/318 [27:01<42:50, 13.18s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 124/318 [27:14<42:37, 13.18s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 125/318 [27:28<42:24, 13.18s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 126/318 [27:41<42:11, 13.18s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 127/318 [27:54<41:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 128/318 [28:07<41:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 129/318 [28:20<41:31, 13.18s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 130/318 [28:34<41:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3058, 'learning_rate': 0.00011823899371069183, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m41%|████      | 130/318 [28:34<41:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 131/318 [28:47<41:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 132/318 [29:00<40:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 133/318 [29:13<40:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 134/318 [29:26<40:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 135/318 [29:39<40:12, 13.18s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 136/318 [29:53<39:59, 13.18s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 137/318 [30:06<39:46, 13.18s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 138/318 [30:19<39:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 139/318 [30:32<39:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 140/318 [30:45<39:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1727, 'learning_rate': 0.00011194968553459119, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 140/318 [30:45<39:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 141/318 [30:59<38:53, 13.18s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 142/318 [31:12<38:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 143/318 [31:25<38:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 144/318 [31:38<38:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 145/318 [31:51<38:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 146/318 [32:04<37:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 147/318 [32:18<37:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 148/318 [32:31<37:21, 13.18s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 149/318 [32:44<37:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 150/318 [32:57<36:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.194, 'learning_rate': 0.00010566037735849057, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 150/318 [32:57<36:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 151/318 [33:10<36:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 152/318 [33:24<36:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 153/318 [33:37<36:15, 13.18s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 154/318 [33:50<36:02, 13.18s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 155/318 [34:03<35:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 156/318 [34:16<35:35, 13.18s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 157/318 [34:29<35:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 158/318 [34:43<35:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 159/318 [34:56<34:56, 13.18s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 160/318 [35:09<34:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1497, 'learning_rate': 9.937106918238994e-05, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m50%|█████     | 160/318 [35:09<34:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 161/318 [35:22<34:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 162/318 [35:35<34:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 163/318 [35:49<34:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 164/318 [36:02<33:49, 13.18s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 165/318 [36:15<33:36, 13.18s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 166/318 [36:28<33:23, 13.18s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 167/318 [36:41<33:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 168/318 [36:55<32:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 169/318 [37:08<32:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 170/318 [37:21<32:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0893, 'learning_rate': 9.308176100628931e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 170/318 [37:21<32:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 171/318 [37:34<32:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 172/318 [37:47<32:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 173/318 [38:00<31:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 174/318 [38:14<31:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 175/318 [38:27<31:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 176/318 [38:40<31:11, 13.18s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 177/318 [38:53<30:58, 13.18s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 178/318 [39:06<30:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 179/318 [39:20<30:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 180/318 [39:33<30:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2102, 'learning_rate': 8.679245283018869e-05, 'epoch': 1.7}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 180/318 [39:33<30:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 181/318 [39:46<30:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 182/318 [39:59<29:52, 13.18s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 183/318 [40:12<29:39, 13.18s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 184/318 [40:25<29:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 185/318 [40:39<29:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 186/318 [40:52<29:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 187/318 [41:05<28:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 188/318 [41:18<28:33, 13.18s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 189/318 [41:31<28:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 190/318 [41:45<28:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2197, 'learning_rate': 8.050314465408806e-05, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 190/318 [41:45<28:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 191/318 [41:58<27:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 192/318 [42:11<27:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 193/318 [42:24<27:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 194/318 [42:37<27:14, 13.18s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 195/318 [42:50<27:01, 13.18s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 196/318 [43:04<26:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 197/318 [43:17<26:35, 13.18s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 198/318 [43:30<26:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 199/318 [43:43<26:08, 13.18s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 200/318 [43:56<25:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1878, 'learning_rate': 7.421383647798742e-05, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 200/318 [43:56<25:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 201/318 [44:10<25:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 202/318 [44:23<25:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 203/318 [44:36<25:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 204/318 [44:49<25:02, 13.18s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 205/318 [45:02<24:49, 13.18s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 206/318 [45:15<24:36, 13.18s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 207/318 [45:29<24:23, 13.19s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 208/318 [45:42<24:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 209/318 [45:55<23:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 210/318 [46:08<23:43, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2532, 'learning_rate': 6.79245283018868e-05, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 210/318 [46:08<23:43, 13.18s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 211/318 [46:21<23:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 212/318 [46:35<23:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 213/318 [46:48<23:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 214/318 [47:01<22:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 215/318 [47:14<22:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 216/318 [47:27<22:24, 13.18s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 217/318 [47:41<22:11, 13.18s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 218/318 [47:54<21:58, 13.18s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 219/318 [48:07<21:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 220/318 [48:20<21:31, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1767, 'learning_rate': 6.163522012578616e-05, 'epoch': 2.08}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 220/318 [48:20<21:31, 13.18s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 221/318 [48:33<21:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 222/318 [48:46<21:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 223/318 [49:00<20:52, 13.18s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 224/318 [49:13<20:39, 13.18s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 225/318 [49:26<20:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 226/318 [49:39<20:12, 13.18s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 227/318 [49:52<19:59, 13.18s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 228/318 [50:06<19:46, 13.18s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 229/318 [50:19<19:33, 13.18s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 230/318 [50:32<19:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0737, 'learning_rate': 5.534591194968554e-05, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 230/318 [50:32<19:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 231/318 [50:45<19:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 232/318 [50:58<18:53, 13.18s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 233/318 [51:11<18:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 234/318 [51:25<18:27, 13.18s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 235/318 [51:38<18:14, 13.18s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 236/318 [51:51<18:01, 13.18s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 237/318 [52:04<17:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 238/318 [52:17<17:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 239/318 [52:31<17:21, 13.18s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 240/318 [52:44<17:08, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.074, 'learning_rate': 4.9056603773584906e-05, 'epoch': 2.26}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 240/318 [52:44<17:08, 13.18s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 241/318 [52:57<16:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 242/318 [53:10<16:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 243/318 [53:23<16:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 244/318 [53:36<16:15, 13.18s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 245/318 [53:50<16:02, 13.18s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 246/318 [54:03<15:49, 13.18s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 247/318 [54:16<15:36, 13.18s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 248/318 [54:29<15:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 249/318 [54:42<15:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 250/318 [54:56<14:56, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1316, 'learning_rate': 4.276729559748428e-05, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 250/318 [54:56<14:56, 13.18s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 251/318 [55:09<14:43, 13.18s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 252/318 [55:22<14:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 253/318 [55:35<14:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 254/318 [55:48<14:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 255/318 [56:01<13:50, 13.18s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 256/318 [56:15<13:37, 13.18s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 257/318 [56:28<13:24, 13.18s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 258/318 [56:41<13:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 259/318 [56:54<12:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 260/318 [57:07<12:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.031, 'learning_rate': 3.647798742138365e-05, 'epoch': 2.45}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 260/318 [57:07<12:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 261/318 [57:21<12:31, 13.18s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 262/318 [57:34<12:18, 13.18s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 263/318 [57:47<12:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 264/318 [58:00<11:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 265/318 [58:13<11:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 266/318 [58:27<11:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 267/318 [58:40<11:12, 13.18s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 268/318 [58:53<10:59, 13.18s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 269/318 [59:06<10:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 270/318 [59:19<10:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.081, 'learning_rate': 3.018867924528302e-05, 'epoch': 2.55}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 270/318 [59:19<10:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 271/318 [59:32<10:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 272/318 [59:46<10:06, 13.18s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 273/318 [59:59<09:53, 13.18s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 274/318 [1:00:12<09:40, 13.18s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 275/318 [1:00:25<09:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 276/318 [1:00:38<09:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 277/318 [1:00:52<09:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 278/318 [1:01:05<08:47, 13.18s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 279/318 [1:01:18<08:34, 13.18s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 280/318 [1:01:31<08:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1191, 'learning_rate': 2.3899371069182393e-05, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 280/318 [1:01:31<08:20, 13.18s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 281/318 [1:01:44<08:07, 13.18s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 282/318 [1:01:57<07:54, 13.18s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 283/318 [1:02:11<07:41, 13.18s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 284/318 [1:02:24<07:28, 13.18s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 285/318 [1:02:37<07:15, 13.18s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 286/318 [1:02:50<07:01, 13.18s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 287/318 [1:03:03<06:48, 13.18s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 288/318 [1:03:17<06:35, 13.18s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 289/318 [1:03:30<06:22, 13.18s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 290/318 [1:03:43<06:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0264, 'learning_rate': 1.761006289308176e-05, 'epoch': 2.74}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 290/318 [1:03:43<06:09, 13.18s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 291/318 [1:03:56<05:55, 13.18s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 292/318 [1:04:09<05:42, 13.18s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 293/318 [1:04:22<05:29, 13.18s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 294/318 [1:04:36<05:16, 13.18s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 295/318 [1:04:49<05:03, 13.18s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 296/318 [1:05:02<04:50, 13.18s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 297/318 [1:05:15<04:36, 13.18s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 298/318 [1:05:28<04:23, 13.18s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 299/318 [1:05:42<04:10, 13.18s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 300/318 [1:05:55<03:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0351, 'learning_rate': 1.1320754716981132e-05, 'epoch': 2.83}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 300/318 [1:05:55<03:57, 13.18s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 301/318 [1:06:08<03:44, 13.18s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 302/318 [1:06:21<03:30, 13.18s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 303/318 [1:06:34<03:17, 13.18s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 304/318 [1:06:47<03:04, 13.18s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 305/318 [1:07:01<02:51, 13.18s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 306/318 [1:07:14<02:38, 13.18s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 307/318 [1:07:27<02:25, 13.18s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 308/318 [1:07:40<02:11, 13.18s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 309/318 [1:07:53<01:58, 13.18s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 310/318 [1:08:07<01:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0231, 'learning_rate': 5.031446540880504e-06, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 310/318 [1:08:07<01:45, 13.18s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 311/318 [1:08:20<01:32, 13.18s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 312/318 [1:08:33<01:19, 13.18s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 313/318 [1:08:46<01:05, 13.18s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 314/318 [1:08:59<00:52, 13.18s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 315/318 [1:09:12<00:39, 13.18s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 316/318 [1:09:26<00:26, 13.18s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 317/318 [1:09:39<00:13, 13.18s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 318/318 [1:09:52<00:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 4192.5216, 'train_samples_per_second': 0.152, 'train_steps_per_second': 0.076, 'train_loss': 1.2019662977014698, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 318/318 [1:09:52<00:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 318/318 [1:09:52<00:00, 13.18s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  7.70it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  4.22it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.65it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.48it/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 8.75MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 138MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 36.5MB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 5.50MB/s]\u001b[0m\n",
      "\u001b[34m2024-02-17 18:41:37,703 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-17 18:41:37,703 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-17 18:41:37,704 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-02-17 18:41:46 Uploading - Uploading generated training model\n",
      "2024-02-17 18:44:13 Completed - Training job completed\n",
      "Training seconds: 5193\n",
      "Billable seconds: 5193\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600861b",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "The SageMaker training job completed in 1.5 hours. The `ml.g5.4xlarge` instance we used costs $1.624 per hour for on-demand usage. \n",
    "\n",
    "As a result, the total cost for training this fine-tuned LLaMa 2 model was only ~$2.44.\n",
    "\n",
    "Now that the fine-tuning is complete, the model is ready for deployment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
